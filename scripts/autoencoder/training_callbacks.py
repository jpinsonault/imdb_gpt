from itertools import islice
import datetime
import logging
from pathlib import Path
import random
import sqlite3
import os
import numpy as np
import torch
from prettytable import PrettyTable
from typing import Any, List, Dict, Optional
from .fields import NumericDigitCategoryField, TextField

def _sample_random_person(conn, tconst):
    q = """
        SELECT p.primaryName,
               p.birthYear,
               p.deathYear,
               GROUP_CONCAT(pp.profession, ',')
        FROM   people p
        LEFT   JOIN people_professions pp ON pp.nconst = p.nconst
        INNER  JOIN principals pr         ON pr.nconst = p.nconst
        WHERE pr.tconst = ? 
          AND p.birthYear IS NOT NULL
        GROUP  BY p.nconst
        HAVING COUNT(pp.profession) > 0
        ORDER  BY RANDOM()
        LIMIT  1
    """
    r = conn.execute(q, (tconst,)).fetchone()
    if not r:
        return None
    return {
        "primaryName": r[0],
        "birthYear":   r[1],
        "deathYear":   r[2],
        "professions": r[3].split(',') if r[3] else None,
    }

def _norm(x): return np.linalg.norm(x) + 1e-9
def _cos(a, b): return float(np.dot(a, b) / (_norm(a) * _norm(b)))

class JointReconstructionLogger:
    """Periodically prints movie↔person reconstructions and embedding similarity."""
    def __init__(
        self,
        movie_ae,
        person_ae,
        db_path,
        interval_steps: int = 200,
        num_samples: int = 4,
        table_width: int = 38,
        max_movie_scan: int = 50000,
        neg_pool: int = 256,
    ):
        self.m_ae = movie_ae
        self.p_ae = person_ae
        self.every = max(1, int(interval_steps))
        self.w = table_width
        self.conn = sqlite3.connect(db_path, check_same_thread=False)

        movies = list(islice(movie_ae.row_generator(), max_movie_scan))
        self.pairs = []
        rng = random.Random(1337)
        candidates = rng.sample(movies, min(num_samples * 3, len(movies)))
        for m in candidates:
            p = self._sample_person(m.get("tconst"))
            if p:
                self.pairs.append((m, p))
            if len(self.pairs) == num_samples:
                break

        neg_movies = rng.sample(movies, min(neg_pool, len(movies)))
        self.neg_people_latents = []
        for m in neg_movies:
            p = self._sample_person(m.get("tconst"))
            if p:
                z = self._encode(self.p_ae, p)
                self.neg_people_latents.append(z)
        if self.neg_people_latents:
            self.neg_people_latents = np.stack(self.neg_people_latents)
        else:
            self.neg_people_latents = np.zeros((1, self.m_ae.latent_dim), dtype=np.float32)

    def _sample_person(self, tconst):
        q = """
        SELECT p.primaryName, p.birthYear, p.deathYear, GROUP_CONCAT(pp.profession, ',')
        FROM people p
        LEFT JOIN people_professions pp ON pp.nconst = p.nconst
        INNER JOIN principals pr ON pr.nconst = p.nconst
        WHERE pr.tconst = ? AND p.birthYear IS NOT NULL
        GROUP BY p.nconst
        HAVING COUNT(pp.profession) > 0
        ORDER BY RANDOM()
        LIMIT 1"""
        r = self.conn.execute(q, (tconst,)).fetchone()
        if not r:
            return None
        return {
            "primaryName":  r[0],
            "birthYear":    r[1],
            "deathYear":    r[2],
            "professions":  r[3].split(',') if r[3] else None,
        }

    @torch.no_grad()
    def _encode(self, ae, row):
        xs = [f.transform(row.get(f.name)) for f in ae.fields]
        xs = [x.unsqueeze(0).to(ae.device) for x in xs]
        z = ae.encoder(xs)
        if isinstance(z, torch.Tensor):
            z = z.detach().cpu().numpy()[0]
        return z

    def _recon(self, ae, z):
        return ae.reconstruct_row(z)

    def _rank(self, z_m, z_p):
        sims = np.dot(self.neg_people_latents, z_m) / (
            (np.linalg.norm(self.neg_people_latents, axis=1) + 1e-9) * (np.linalg.norm(z_m) + 1e-9)
        )
        sims = np.append(sims, _cos(z_m, z_p))
        return int((-sims).argsort().tolist().index(len(sims) - 1)) + 1

    def _tensor_to_string(self, field, main_tensor, flag_tensor=None):
        try:
            if isinstance(field, NumericDigitCategoryField):
                arr = np.array(main_tensor)
                if arr.ndim == 3:
                    return field.to_string(arr)
                return field.to_string(arr.flatten())
            if hasattr(field, "tokenizer") and field.tokenizer is not None:
                return field.to_string(main_tensor, flag_tensor)
            arr = np.array(main_tensor)
            if arr.ndim > 1:
                arr = arr.flatten()
            return field.to_string(arr, flag_tensor)
        except Exception:
            return "[Conversion Error]"

    def _roundtrip_string(self, field, raw_value):
        try:
            t = field.transform(raw_value)
            if isinstance(t, (list, tuple)):
                t = t[0]
            return self._tensor_to_string(field, t)
        except Exception:
            return "[RT Error]"

    def on_batch_end(self, global_step: int):
        if self.every <= 0:
            return
        if (global_step + 1) % self.every != 0:
            return

        for m_row, p_row in self.pairs:
            z_m = self._encode(self.m_ae, m_row)
            z_p = self._encode(self.p_ae, p_row)

            cos = _cos(z_m, z_p)
            l2 = float(np.linalg.norm(z_m - z_p))
            ang = float(np.degrees(np.arccos(max(min(cos, 1.0), -1.0))))
            rank = self._rank(z_m, z_p)

            m_rec = self._recon(self.m_ae, z_m)
            p_rec = self._recon(self.p_ae, z_p)

            tm = PrettyTable(["Movie field", "orig", "round", "recon"])
            for f in self.m_ae.fields:
                o = m_row.get(f.name, "")
                rt = self._roundtrip_string(f, o)
                r = m_rec.get(f.name, "")
                tm.add_row([f.name, str(o)[: self.w], rt[: self.w], str(r)[: self.w]])

            tp = PrettyTable(["Person field", "orig", "round", "recon"])
            for f in self.p_ae.fields:
                o = p_row.get(f.name, "")
                rt = self._roundtrip_string(f, o)
                r = p_rec.get(f.name, "")
                tp.add_row([f.name, str(o)[: self.w], rt[: self.w], str(r)[: self.w]])

            bar_len = 20
            filled = max(0, min(bar_len, int(round(cos * bar_len))))
            bar = "#" * filled + "-" * (bar_len - filled)
            print(
                f"\n--- joint recon @ step {global_step+1} ---\n"
                f"cos={cos:.3f}  angle={ang:5.1f}°  l2={l2:.3f}  rank@neg={rank}\n"
                f"[{bar}]\n"
                f"{tm}\n{tp}"
            )

class TensorBoardPerBatchLogger:
    """Writes basic scalars to a unique TensorBoard run directory."""
    def __init__(self, log_dir: str, run_prefix: str = "run"):
        from torch.utils.tensorboard import SummaryWriter
        root = Path(log_dir)
        ts = datetime.datetime.now().strftime("%Y-%m-%d_%H%M")
        base = f"{run_prefix}_{ts}"
        run_dir = root / base
        if run_dir.exists():
            i = 1
            while True:
                cand = root / f"{base}_{i}"
                if not cand.exists():
                    run_dir = cand
                    break
                i += 1
        run_dir.parent.mkdir(parents=True, exist_ok=True)
        self.writer = SummaryWriter(log_dir=str(run_dir))
        self.run_dir = str(run_dir)

    def log_scalars(self, step: int, scalars: Dict[str, float]):
        for k, v in scalars.items():
            self.writer.add_scalar(k, float(v), step)

    def flush(self):
        self.writer.flush()

    def close(self):
        self.writer.flush()
        self.writer.close()

class ModelSaveHook:
    """Calls row_autoencoder.save_model() on epoch end."""
    def __init__(self, row_autoencoder, output_dir: str):
        self.row_autoencoder = row_autoencoder
        self.output_dir = output_dir

    def on_epoch_end(self, epoch: int):
        self.row_autoencoder.save_model()
        print(f"Model saved to {self.output_dir} at the end of epoch {epoch + 1}")

class RowReconstructionLogger:
    """Prints reconstructions for a single RowAutoencoder at intervals."""
    def __init__(
        self,
        interval_steps: int,
        row_autoencoder,
        db_path: str,
        num_samples: int = 5,
        table_width: int = 40,
    ):
        self.interval_steps = max(1, int(interval_steps))
        self.row_autoencoder = row_autoencoder
        self.db_path = db_path
        self.num_samples = num_samples
        self.w = table_width

        if not self.row_autoencoder.stats_accumulated:
            self.row_autoencoder.accumulate_stats()

        all_rows = list(self.row_autoencoder.row_generator())
        n = min(num_samples, len(all_rows))
        self.samples = random.sample(all_rows, n) if n > 0 else []

    @torch.no_grad()
    def _encode(self, row):
        xs = [f.transform(row.get(f.name)) for f in self.row_autoencoder.fields]
        xs = [x.unsqueeze(0).to(self.row_autoencoder.device) for x in xs]
        z = self.row_autoencoder.encoder(xs)
        return z.detach()

    @torch.no_grad()
    def _decode(self, z_tensor):
        outs = self.row_autoencoder.decoder(z_tensor)
        return [o.detach().cpu().numpy()[0] for o in outs]

    def _tensor_to_string(self, field, main_tensor: np.ndarray) -> str:
        try:
            if isinstance(field, NumericDigitCategoryField):
                arr = np.array(main_tensor)
                return field.to_string(arr if arr.ndim == 2 else arr.flatten())
            if hasattr(field, "tokenizer") and field.tokenizer is not None:
                return field.to_string(np.array(main_tensor))
            arr = np.array(main_tensor)
            if arr.ndim > 1:
                arr = arr.flatten()
            return field.to_string(arr)
        except Exception:
            return "[Conversion Error]"

    def on_batch_end(self, global_step: int):
        if not self.samples:
            return
        if (global_step + 1) % self.interval_steps != 0:
            return

        print(f"\nBatch {global_step + 1}: Reconstruction Demo")
        for i, row_dict in enumerate(self.samples):
            print(f"\nSample {i + 1}:")
            table = PrettyTable()
            table.field_names = ["Field", "Original Value", "Reconstructed"]
            table.align = "l"
            for col in ["Original Value", "Reconstructed"]:
                table.max_width[col] = self.w

            z = self._encode(row_dict)
            preds = self._decode(z)

            for field, pred in zip(self.row_autoencoder.fields, preds):
                field_name = field.name
                original_raw = row_dict.get(field_name, "N/A")
                original_str = ", ".join(map(str, original_raw)) if isinstance(original_raw, list) else str(original_raw)
                reconstructed_str = self._tensor_to_string(field, pred)
                table.add_row([field_name, original_str, reconstructed_str])

            print(table)
class SequenceReconstructionLogger:
    def __init__(self, movie_ae, people_ae, predictor, db_path: str, seq_len: int, interval_steps: int = 200, num_samples: int = 2, table_width: int = 38):
        import sqlite3, random
        from itertools import islice
        self.m_ae = movie_ae
        self.p_ae = people_ae
        self.pred = predictor
        self.seq_len = seq_len
        self.every = max(1, int(interval_steps))
        self.w = table_width
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        movies = list(islice(self.m_ae.row_generator(), 50000))
        rng = random.Random(7331)
        rng.shuffle(movies)
        self.samples = []
        for m in movies:
            ppl = self._people_for(m.get("tconst"))
            if ppl:
                if len(ppl) < self.seq_len:
                    ppl = ppl + [ppl[-1]] * (self.seq_len - len(ppl))
                else:
                    ppl = ppl[: self.seq_len]
                self.samples.append((m, ppl))
            if len(self.samples) == num_samples:
                break

    def _people_for(self, tconst: str):
        q = """
        SELECT p.primaryName, p.birthYear, p.deathYear, GROUP_CONCAT(pp.profession, ',')
        FROM people p
        LEFT JOIN people_professions pp ON pp.nconst = p.nconst
        INNER JOIN principals pr ON pr.nconst = p.nconst
        WHERE pr.tconst = ? AND p.birthYear IS NOT NULL
        GROUP BY p.nconst
        HAVING COUNT(pp.profession) > 0
        ORDER BY pr.ordering
        LIMIT ?
        """
        r = self.conn.execute(q, (tconst, self.seq_len)).fetchall()
        out = []
        for row in r:
            out.append({
                "primaryName": row[0],
                "birthYear": row[1],
                "deathYear": row[2],
                "professions": row[3].split(",") if row[3] else None,
            })
        return out

    def _tensor_to_string(self, field, arr):
        import numpy as np
        try:
            a = np.array(arr)
            if hasattr(field, "tokenizer") and field.tokenizer is not None:
                return field.to_string(a)
            return field.to_string(a.flatten() if a.ndim > 1 else a)
        except Exception:
            return "[conv_err]"

    @torch.no_grad()
    def _predict_seq(self, movie_row):
        device = next(self.pred.parameters()).device
        xs = [f.transform(movie_row.get(f.name)) for f in self.m_ae.fields]
        xs = [x.unsqueeze(0).to(device) for x in xs]
        outs = self.pred(xs)
        return [o.detach().cpu().numpy()[0] for o in outs]

    def on_batch_end(self, global_step: int):
        if not self.samples:
            return
        if (global_step + 1) % self.every != 0:
            return
        from prettytable import PrettyTable
        for m_row, ppl in self.samples:
            preds = self._predict_seq(m_row)
            print("\nSequence reconstruction")
            print(f"movie: {m_row.get('primaryTitle', '')}")
            for t in range(self.seq_len):
                tab = PrettyTable(["field", "orig", "recon"])
                tab.align = "l"
                for f, pred in zip(self.p_ae.fields, preds):
                    y = pred[t]
                    orig_raw = ppl[t].get(f.name, "")
                    if isinstance(orig_raw, list):
                        orig_str = ", ".join(map(str, orig_raw))
                    else:
                        orig_str = str(orig_raw)
                    recon_str = self._tensor_to_string(f, y)
                    tab.add_row([f.name, orig_str[: self.w], recon_str[: self.w]])
                print(f"\ntimestep {t+1}/{self.seq_len}\n{tab}")
